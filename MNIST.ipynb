{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "p3-MNIST-classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSi49U-E899I"
      },
      "source": [
        "Autor: Professor Edson C. V. Júnior\n",
        "\n",
        "Linkedin: https://www.linkedin.com/in/edson-j%C3%BAnior-032a66162/\n",
        "\n",
        "OBS: Algumas partes de códigos foram extraídos do [notebook](https://github.com/ageron/handson-ml) do Aurélien Géron.\n",
        "\n",
        " O Aurélien conta com um excelente livro na área de ML [(Link de afiliado aqui).](https://www.amazon.com.br/gp/product/B07XGF2G87/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=B07XGF2G87&linkCode=as2&tag=edsonjr0d-20&linkId=a0ddf45ae58cc1908c6511cdca2b5c5e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbuf2o-UZL-x"
      },
      "source": [
        "#MNIST\n",
        "\n",
        "Neste pequeno notebook ilustraremos a aplicação de alguns conceitos de Machine Learning relativas ao problema de classificação de dígitos. Devido ao tamanho do dataset, não é intenção do notebook fazer otimizações de modelos, mas tão somente ilustrar alguns conceitos tais como:\n",
        "\n",
        "*   Visualização de imagens à partir de matrizes em escalas de cinza\n",
        "*   SGDClassifier (sklearn)\n",
        "*   GridSearch\n",
        "*   Tópicos em classificação multiclasse\n",
        "\n",
        "Bom aprendizado!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hHU7cjTZL-_"
      },
      "source": [
        "# Configurações iniciais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TOFvglyZL_A"
      },
      "source": [
        "\n",
        "Inicialmente, vamos importar alguns módulos comuns e configurar o matplotlib para funcionar mais elegantemente, além de configurar um módulo para salvar figuras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZGRnOQ5ZL_B"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "\n",
        "# Para ajudar na reproducibilidade\n",
        "# Aqui a seed é 42, mas não há nada de especial nisso\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(fig_id, format='png', dpi=600)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKM38I6yZL_C"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMVcnYnFYcmx"
      },
      "source": [
        "Vamos agora importar o [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database), que um largo conjunto de dados que contém anotações à mão de dígitos, de 0 à 9. \n",
        "\n",
        "É um dataset muito utilizado para aprendizado, assim como referência quando se pretende testar novos algoritmos de classificação.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz4ZuB2AZCV2"
      },
      "source": [
        " Vamos precisar importar o conjunto de dados. O sklearn já vem com uma rotina para buscar alguns datasets públicos, como é caso do MNIST. Para isso vamos utilizar 'fetch_openml()' para buscar o nosso conjunto de dados.\n",
        "\n",
        "<font color= '#5A35B6'>**Atenção:**</font>  A função `fetch_mldata()` está obsoleta desde o Scikit-Learn 0.20. Devemos, ao invés disso, utilizar o `fetch_openml()`. Observa que seguindo as boas práticas de ML, a nova função já retorna o MNIST de forma não ordenada, enquanto que `fetch_mldata()` retorna o conjunto de dados ordenados pelo rótulo. Poderá então haver diferenças dependendo da versão que você utilizar. Recomenda-se que você atualize a sua versão do sklearn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUuGpUJFbxnV"
      },
      "source": [
        "#Importando dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version= 1, as_frame= False)\n",
        "mnist.keys()\n",
        "mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6iYdbpycU0U"
      },
      "source": [
        "Vejamos o tipo dos dados que temos a nossa disposição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDLg5otOcJ6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364fe5e7-f3d9-4791-acc5-e6fc8206d3b7"
      },
      "source": [
        "type(mnist)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhwwkcB5cbj1"
      },
      "source": [
        "Esse tipo de dados é uma espécie de container implementada no Sklearn. Os elementos devem ser acessado através de \"chaves\" que dão acesso ao conjunto de dados. Para acessar as features, usamos a chave \"data\", ao passo que para acessar os rótulos usamos \"target\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCc7FleEb-5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59819d0-9051-46f4-b967-0ee8f061fd0e"
      },
      "source": [
        "mnist[\"data\"], mnist[\"target\"]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " array([5, 0, 4, ..., 4, 5, 6], dtype=int8))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPnpBW_dFud"
      },
      "source": [
        "Você poderia também acessar como se fosse um atributo do objeto mnist:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_havl2iIdAkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553c41e2-977d-435d-80b7-fcf219873821"
      },
      "source": [
        "mnist.data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOyFcyoLdLjw"
      },
      "source": [
        "Vejamos as dimensões da matriz \"mnist.data\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cngv8cTDZL_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee501bde-b816-45c6-fda9-35145fee7d93"
      },
      "source": [
        "mnist.data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8LX_nlydQbu"
      },
      "source": [
        "Agora vamos instanciar as features do problemas em uma matriz X e os rótulos no vetor y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1lTRg2ZL_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5ea711-f12e-4285-c284-adbb27d431c4"
      },
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyetdzuwdiSY"
      },
      "source": [
        "Temos um total de 70000 instâncias e 784 features/características. Vamos agora tentar entender melhor do que se tratam essas 784 características.\n",
        "\n",
        "Primeiramente, devemos lembrar que os nossos dados são \n",
        "<font color= '#5A35B6'>**imagens**</font>. Para ser mais preciso, as 784 representam as intesidades, na escala preto e branco, de cada pixel de uma imagem quadrada com 28px em cada dimensão. \n",
        "\n",
        "Note que 28*28 = 784.\n",
        "\n",
        "Vamos agora pegar um dígito, redimensionar em 28 por 28 pixels e visualizar essa imagem.\n",
        "\n",
        "A seguir, chamamos o \"plt\" do matplotlib, colocando como argumento três paramêmtros:\n",
        "\n",
        "- A matriz que representa a imagem;\n",
        "\n",
        "- O mapeamento de cores (color map - cmap). No nosso caso, usaremos inicialmente um esquema binário preto e branco;\n",
        "\n",
        "- Método de interpolação: originalmente a nossa imagem tem dimensões 28X28 em pixels, ao passo que o matplotlib pode dispor a imagem em outras dimensões, requerendo uma técnica \"interpolação\" para preencher pixels faltando quando redimensionamos a imagem. Para essa finalidade, recomendo usar o método a seguir usando três técnicas: 'nearest', 'gaussian' e 'lanczos'. Em cada uma delas execute o código, que vai gerar uma imagem, após isso abra a imagem em outra aba e afaste (ctrl --) e aproxime (ctrl ++) a imagem para entender esse efeito da interpolação.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HGUPU6GZL_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "4ed15b82-4484-4a78-d4f6-60c7ac05cfa5"
      },
      "source": [
        "some_digit = X[36000]\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "\n",
        "plt.imshow(some_digit_image, \n",
        "           cmap = mpl.cm.binary,\n",
        "           interpolation= 'nearest')\n",
        "\n",
        "plt.axis(\"off\") #para desligar os eixos da imagem\n",
        "\n",
        "save_fig(\"some_digit_plot\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving figure some_digit_plot\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZPAQHWnjwx3"
      },
      "source": [
        "Vejamos o rótulo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvC9SJHFjvaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251cdbac-9534-48f6-ca4a-1a0d1b49fdf5"
      },
      "source": [
        "y[36000]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmCsEWTrjjsX"
      },
      "source": [
        "Vamos agora definir uma função que servirá para plotar as imagens, que basicamente organiza o código que ilustramos anteriormente, podendo ser chamado várias vezes se quisermos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKQW4no6ZL_K"
      },
      "source": [
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary,\n",
        "               interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOv5FuLwkAIH"
      },
      "source": [
        "Agora vamos separa o nosso conjunto de treino e teste. Observe que não precisaríamos embaralhar os dados pois eles já vieram embaralhados!\n",
        "\n",
        "Mas vamo embaralhar apenas que você não se esqueça desse detalhe muito importante.\n",
        "\n",
        "Aqui estaremos utilizando 60000 imagens para treino e 10000 para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWbFBiAoZL_O"
      },
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dAVZrvfZL_O"
      },
      "source": [
        "#Embaralhemento \n",
        "shuffle_index = np.random.permutation(60000)\n",
        "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD74VS7XZL_m"
      },
      "source": [
        "# Multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ3_Xd0b31A8"
      },
      "source": [
        "Agora vamos usar o conjunto de treinamento através de um esquema de validação cruzada para eleger o modelo mais indicado para o nosso problema. \n",
        "\n",
        "Antes disso faça um estudo sobre modelos lineares que usam Gradiente Descendente Estocástico (SGD):\n",
        "\n",
        "- Faça uma leitura sobre assunto no [**guia do usuário**](https://scikit-learn.org/stable/modules/sgd.html#sgd) do sklearn. De acordo com o guia, esses modelos lineares são bem importantes para classificação de textos e processamento natural de linguagem (NLP);\n",
        "\n",
        "- Dê uma olhada no [**SGDClassifier do sklearn**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier). Leia os parágrafos inciais da documemtanção até parte que inicia a descrição dos parâmetros da classe, preste atenção principalmente nos parâmetros: \"loss\", \"penalty\" e \"alpha\".\n",
        "\n",
        "Vamos fazer uma otimização através dos seguintes parâmetros:\n",
        "\n",
        "loss : ['hinge', 'log']\n",
        "\n",
        "alpha: [1e-4,  1e-2,  1]\n",
        "\n",
        "Pode-se incluir a penalização também, mas evitaremos muitos parâmetros pois o treinamento é demorado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxMAoACmRwIo",
        "outputId": "af1f3ec8-cae5-40e2-8b33-2d4195c8a49b"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline #Para criar um pipeline!\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipe = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ]) #O nosso modelo passará pelo std_scaler e depois pelo estimador\n",
        "\n",
        "#Usaremos 10 epochs, por isso max_iter = 10 \n",
        "#Cuidado, valores alto de max_iter fazem o algortirmo demorar\n",
        "#Outros valores para max_iter ou random_state, vão alterar o resultado\n",
        "\n",
        "param_grid = [{'estimator__loss' : ['hinge', 'log'],\n",
        "               'estimator__alpha': [1e-4, 1e-2, 1],\n",
        "               }] #grade de parâmetros para testar\n",
        "\n",
        "\"\"\"É necessário colocar o prefixo estimator__ para indicar que os parâmetros \n",
        "serão aplicados ao estimador. Você poderia tentar otimizar o pré-processamento\n",
        "dentro do pipeline também! Mas observa que muitos parâmetros tornam o processo\n",
        "bem demora.\n",
        "\"\"\"\n",
        "\n",
        "#Quanto maior o verbose no GridSearch, mais detalhes sobre o processo\n",
        "#n_jobs = -1 signifca o número de cores da máquina (-1 usa todos)\n",
        "grid_search = GridSearchCV(pipe, param_grid, cv=5, verbose=10, n_jobs=1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV 1/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.912 total time=   9.3s\n",
            "[CV 2/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.916 total time=   8.6s\n",
            "[CV 3/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.909 total time=   8.6s\n",
            "[CV 4/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.912 total time=   8.6s\n",
            "[CV 5/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.910 total time=   8.6s\n",
            "[CV 1/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.912 total time=  13.9s\n",
            "[CV 2/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.916 total time=  13.8s\n",
            "[CV 3/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.908 total time=  14.3s\n",
            "[CV 4/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.911 total time=  13.9s\n",
            "[CV 5/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.909 total time=  14.3s\n",
            "[CV 1/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.898 total time=   8.6s\n",
            "[CV 2/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.897 total time=   8.7s\n",
            "[CV 3/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.892 total time=   8.8s\n",
            "[CV 4/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.898 total time=   8.7s\n",
            "[CV 5/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.891 total time=   8.9s\n",
            "[CV 1/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.897 total time=  15.1s\n",
            "[CV 2/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.899 total time=  14.9s\n",
            "[CV 3/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.892 total time=  15.0s\n",
            "[CV 4/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.895 total time=  14.9s\n",
            "[CV 5/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.892 total time=  14.8s\n",
            "[CV 1/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 1/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.859 total time=   6.8s\n",
            "[CV 2/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 2/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.864 total time=   6.8s\n",
            "[CV 3/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 3/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.863 total time=   6.8s\n",
            "[CV 4/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 4/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.873 total time=   6.8s\n",
            "[CV 5/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 5/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.859 total time=   6.9s\n",
            "[CV 1/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.830 total time=  11.8s\n",
            "[CV 2/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.846 total time=  11.8s\n",
            "[CV 3/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.839 total time=  12.3s\n",
            "[CV 4/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.847 total time=  12.8s\n",
            "[CV 5/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.838 total time=  12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                                       ('estimator',\n",
              "                                        SGDClassifier(max_iter=10,\n",
              "                                                      random_state=42))]),\n",
              "             n_jobs=1,\n",
              "             param_grid=[{'estimator__alpha': [0.0001, 0.01, 1],\n",
              "                          'estimator__loss': ['hinge', 'log']}],\n",
              "             verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFq2z3afc_0i"
      },
      "source": [
        "Vamos agora visualizar os resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20dhXNEAcZhP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "d0bb4e7c-27e1-46f8-81a4-1ab9cf001790"
      },
      "source": [
        "results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_['std_test_score'], \n",
        "                                  columns=[\"Std\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], \n",
        "                                  columns=[\"Score\"])],axis=1)\n",
        "\n",
        "results.sort_values(\"Score\", ascending=False) #Ordenamento decrescente"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-26249fca-e386-49a7-a4fd-620497193f44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator__alpha</th>\n",
              "      <th>estimator__loss</th>\n",
              "      <th>Std</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>0.911800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>log</td>\n",
              "      <td>0.002614</td>\n",
              "      <td>0.911333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.003303</td>\n",
              "      <td>0.895133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>log</td>\n",
              "      <td>0.002763</td>\n",
              "      <td>0.894883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.005083</td>\n",
              "      <td>0.863683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>log</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>0.840233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26249fca-e386-49a7-a4fd-620497193f44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26249fca-e386-49a7-a4fd-620497193f44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26249fca-e386-49a7-a4fd-620497193f44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   estimator__alpha estimator__loss       Std     Score\n",
              "0            0.0001           hinge  0.002276  0.911800\n",
              "1            0.0001             log  0.002614  0.911333\n",
              "2            0.0100           hinge  0.003303  0.895133\n",
              "3            0.0100             log  0.002763  0.894883\n",
              "4            1.0000           hinge  0.005083  0.863683\n",
              "5            1.0000             log  0.006217  0.840233"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvvD-tfVaS-0"
      },
      "source": [
        "<font color= '#5A35B6'>**Observações**</font> importantes:\n",
        "\n",
        "\n",
        "\n",
        "* Fazendo uma análise preliminar, há indícios de que uma regularização l2 com alpha 0.0001 fornece as melhores respostas. Observa ainda que o modelo está indicado que está havendo subajuste (menor alpha, menos regularização), o que indica que deveríamos procurar um modelo mais complexo para a situação.\n",
        "\n",
        "*   Outro fato importante de se observar é que não estipulamos o \"score\" no gridSearch e nesse caso o score será herdado do estimador. No nosso exemplo o SGDClassifier por padrão calcula a acurácia, então o score na tabela significa acurácia. \n",
        "\n",
        "Vamos agora treinar um modelo com os melhores parametros do GridSearch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ3H65RnvUX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2f2448-3992-41ad-84b3-d76b8ef15265"
      },
      "source": [
        "model = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ])\n",
        "\n",
        "model.set_params(**grid_search.best_params_) #Introduz no pipeline os parametros\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                ('estimator', SGDClassifier(max_iter=10, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di-dwmsvx_Hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f84ba6-ecfd-41b4-d3e7-648d0138e37a"
      },
      "source": [
        "#Treinando o modelo\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                ('estimator', SGDClassifier(max_iter=10, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LByZLgUJiWYg"
      },
      "source": [
        "Vamos agora pegar um elemento do conjunto de teste para dar uma pequena espiada se o modelo está funcionando. \n",
        "\n",
        "<font color= '#5A35B6'>**Cuidado**</font>: Teoricamente não se deve usar o conjunto de teste até o final do processo. Então devemos utilizar ele agora. Mas se quisermos ser bem rigorosos, no final bastaria não considerar essa única instância que faríamos esse teste preliminar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rniEmReNgQCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2c11fd-8a30-4cde-9d90-fbbdcbde8178"
      },
      "source": [
        "#Instanciando e treinando um digito em espcifico:\n",
        "some_digit = X_test[0]\n",
        "model.predict([some_digit])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACv01oXyyhoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf8df08-6e19-4ac7-a527-25e513555c8f"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxsO-wgEykAF"
      },
      "source": [
        "O resultado foi o esperado? \n",
        "\n",
        "O SGD é treinado em um esquema OvR, de forma que cada classe tem um estimador associado. Dessa forma, cada estimador fornece um score correspondente a uma certa classe, de forma que o algoritmo rotula a nova instância com o estimador que obteve o maior score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZys7jYGZL_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75669ade-890e-449c-e35e-f0425919a630"
      },
      "source": [
        "some_digit_scores = model.decision_function([some_digit])\n",
        "some_digit_scores"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1151.02879743, -1556.65704299, -1625.00768203,  -723.7029964 ,\n",
              "        -1224.37804869, -1266.90999103, -2350.40223502,   282.94034641,\n",
              "        -1326.0511831 ,  -306.38372845]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPV7z783ZL_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b797fec-6611-4f71-a699-f082d176d0fa"
      },
      "source": [
        "np.argmax(some_digit_scores)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm_tGokWZL_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0678bb7-2b67-4b00-a4aa-f17f8ac89979"
      },
      "source": [
        "model.classes_"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yIa_JG5zT-l"
      },
      "source": [
        "Agora nós faremos uma coisa interessante: \n",
        "\n",
        "Vamos forçar o SGD a usar esquema OvO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIBJMbkwZL_p"
      },
      "source": [
        "#classe que implementa OvO na força\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "#Vamos aumentar o número de iterações.\n",
        "#Lembra que na técnica OvO há mais treinamentos mas pode ser interessante \n",
        "#quando o modelo sofre com a escala\n",
        "\n",
        "model = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 1000, random_state=42))\n",
        "             ])\n",
        "\n",
        "model.set_params(**grid_search.best_params_)\n",
        "ovo_clf = OneVsOneClassifier(model)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I07NohmM0jLW"
      },
      "source": [
        "Façamos uma validação cruzada para verificar o desempenho:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49wQQzUg0dRB"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(ovo_clf, X_train, y_train, cv=5)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgqBycS51fio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9ad1be-f0c3-4020-ff0e-53bb11e66b71"
      },
      "source": [
        "scores"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.91583333, 0.91516667, 0.91408333, 0.91916667, 0.91333333])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J2koe521hw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebbb406-b929-4c31-b702-edef00dbda88"
      },
      "source": [
        "np.mean(scores)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9155166666666666"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC5ISJWL1yL2"
      },
      "source": [
        "Vamos treinar no conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBmoBigu0IZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6491fa8-547e-42c1-b97b-d5391951c4c2"
      },
      "source": [
        "ovo_clf.fit(X_train, y_train)\n",
        "ovo_clf.predict([some_digit])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yUB8PpT00sS"
      },
      "source": [
        "Como temos 10 classes ao todo, no esquema OvO treinamos um total de  $\\displaystyle C_{10, 2} = \\frac{10!}{(10-2)! 2! } = 45$ modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrK08FtzZL_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5502f233-1ccd-445a-cfab-d993c93d2957"
      },
      "source": [
        "len(ovo_clf.estimators_)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypu3G4aF3kbM"
      },
      "source": [
        "Agora vamos preparar o nosso modelo para uma avaliação final no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCEcaJ64ZL_r"
      },
      "source": [
        "from sklearn.metrics  import confusion_matrix"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDzbfuKlZL_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a97d47-5796-46c1-8a1f-c6ec6aa81a8f"
      },
      "source": [
        "y_pred = ovo_clf.predict(X_test)\n",
        "conf_mx = confusion_matrix(y_test, y_pred)\n",
        "conf_mx"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 943,    0,   11,    2,    1,   10,    8,    2,    3,    0],\n",
              "       [   0, 1102,   11,    3,    0,    1,    1,    4,   13,    0],\n",
              "       [   4,    4,  970,   13,    2,    2,    5,    7,   21,    4],\n",
              "       [   3,    0,   18,  925,    1,   29,    1,    7,   22,    4],\n",
              "       [   2,    1,   17,    0,  922,    0,    2,    7,    8,   23],\n",
              "       [   6,    1,    6,   34,    5,  789,   10,    3,   31,    7],\n",
              "       [   8,    3,   25,    3,    9,   24,  884,    0,    2,    0],\n",
              "       [   0,    4,   25,   18,    3,    1,    0,  948,    5,   24],\n",
              "       [   5,    1,   10,   31,    7,   23,    5,    4,  882,    6],\n",
              "       [   5,    6,    6,    9,   37,    6,    0,   29,   22,  889]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FaDkhi95qFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db56692-419a-4629-815e-43e0bcdd7aca"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9254"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG_uFcNS-Q6f"
      },
      "source": [
        "#Agora é a sua vez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwaYz6k8-U63"
      },
      "source": [
        "Agora você deve repetir o processo, mas utilizando uma etapa de pré-processamento chamando \"data augmentation\". No caso de imagens, essa técnica pode consistir de diversas metodologias, como: aumentar o número de instâncias de treinamento com rotações e translações das imagens. \n",
        "\n",
        "Nesse caso, a tua missão é treinar um novo modelo no MNIST utilizando translações no conjunto de treinamento. Fazendo isso, ensinamos o modelo a não esperar a figura centrada na imagem, podendo aumentar sua performance no teste. \n",
        "\n",
        "**Sua tarefa:**\n",
        "\n",
        "- Crie uma função  para aumentar o conjunto de **treinamento**, de forma a fazer translações nas imagens. Após isso, você deve treinar o SGDClassifier nesse conjunto de dados aumentado.\n",
        "\n",
        "- Teste o modelo no mesmo conjunto de teste que eu separei - isso é apenas um artifício didático para comparar o data augmentation, a partir do segundo teste a estimativa do erro de generalização deveria ser corrigida se quisermos obter uma estiva de performance!\n",
        "\n",
        "\n",
        "Se você estiver com dificuldades, veja a solução do exercício 2 aqui nesse [notebook](https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb) do A. Géron."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarefa"
      ],
      "metadata": {
        "id": "cnR94GhHz71i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Começamos criando a função que realizará as translações das imagens:"
      ],
      "metadata": {
        "id": "qh6LIkmIAJeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage.interpolation import shift\n",
        "\n",
        "def shift_image(image, ox, oy):\n",
        "    image = image.reshape((28, 28))\n",
        "    shifted_image = shift(image, [oy, ox], cval=0, mode=\"constant\")\n",
        "    return shifted_image.reshape([-1])"
      ],
      "metadata": {
        "id": "ixlu1eCz3Od3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos aumentar nosso conjunto de treino em 9 vezes por meio de algumas translações. Manteremos uma cópia do conjunto original e faremos 8 translações, as quais são dadas pelos pontos (1, 0), (-1, 0), (0, 1), (0, -1), (-1,1), (1,-1), (1,1) e (-1,-1).\n"
      ],
      "metadata": {
        "id": "nFGU_qGXALlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_augmented = [image for image in X_train]\n",
        "y_train_augmented = [label for label in y_train]\n",
        "\n",
        "for ox, oy in ((1, 0), (-1, 0), (0, 1), (0, -1), (-1,1), (1,-1), (1,1), (-1,-1)):\n",
        "    for image, label in zip(X_train, y_train):\n",
        "        X_train_augmented.append(shift_image(image, ox, oy))\n",
        "        y_train_augmented.append(label)\n",
        "\n",
        "X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)"
      ],
      "metadata": {
        "id": "wiIZlQz03Z7p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos agora o embaralhamento do novo conjunto de treino:"
      ],
      "metadata": {
        "id": "VWhVhQAFA7Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
        "X_train_augmented = X_train_augmented[shuffle_idx]\n",
        "y_train_augmented = y_train_augmented[shuffle_idx]"
      ],
      "metadata": {
        "id": "dJzePYuF33DI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faremos uma otimização do SGD com os parâmetros loss e alpha; usaremos as combinações hinge e log para loss e para alpha 1e-4, 1e-2 e 1."
      ],
      "metadata": {
        "id": "_0IWbJ80BKAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ])\n",
        "\n",
        "param_grid = [{'estimator__loss' : ['hinge', 'log'],\n",
        "               'estimator__alpha': [1e-4, 1e-2, 1],\n",
        "               }] \n",
        "              \n",
        "grid_search = GridSearchCV(pipe, param_grid, cv=5, verbose=10, n_jobs=1)\n",
        "grid_search.fit(X_train_augmented, y_train_augmented)"
      ],
      "metadata": {
        "id": "-wjI9rXg4OmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03cb0b3-dabd-4e81-d977-c4a1884ef1d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV 1/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.825 total time= 1.5min\n",
            "[CV 2/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.824 total time= 1.5min\n",
            "[CV 3/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.822 total time= 1.4min\n",
            "[CV 4/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.822 total time= 1.5min\n",
            "[CV 5/5; 1/6] START estimator__alpha=0.0001, estimator__loss=hinge..............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 1/6] END estimator__alpha=0.0001, estimator__loss=hinge;, score=0.821 total time= 1.5min\n",
            "[CV 1/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.825 total time= 2.5min\n",
            "[CV 2/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.823 total time= 2.5min\n",
            "[CV 3/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.823 total time= 2.5min\n",
            "[CV 4/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.819 total time= 2.5min\n",
            "[CV 5/5; 2/6] START estimator__alpha=0.0001, estimator__loss=log................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 2/6] END estimator__alpha=0.0001, estimator__loss=log;, score=0.824 total time= 2.6min\n",
            "[CV 1/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.845 total time= 1.5min\n",
            "[CV 2/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.844 total time= 1.5min\n",
            "[CV 3/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.840 total time= 1.5min\n",
            "[CV 4/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.840 total time= 1.4min\n",
            "[CV 5/5; 3/6] START estimator__alpha=0.01, estimator__loss=hinge................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 3/6] END estimator__alpha=0.01, estimator__loss=hinge;, score=0.843 total time= 1.4min\n",
            "[CV 1/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.843 total time= 2.4min\n",
            "[CV 2/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.842 total time= 2.5min\n",
            "[CV 3/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.840 total time= 2.4min\n",
            "[CV 4/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.841 total time= 2.3min\n",
            "[CV 5/5; 4/6] START estimator__alpha=0.01, estimator__loss=log..................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 4/6] END estimator__alpha=0.01, estimator__loss=log;, score=0.841 total time= 2.4min\n",
            "[CV 1/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 1/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.795 total time= 1.1min\n",
            "[CV 2/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 2/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.792 total time= 1.1min\n",
            "[CV 3/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 3/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.790 total time= 1.2min\n",
            "[CV 4/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 4/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.796 total time= 1.1min\n",
            "[CV 5/5; 5/6] START estimator__alpha=1, estimator__loss=hinge...................\n",
            "[CV 5/5; 5/6] END estimator__alpha=1, estimator__loss=hinge;, score=0.795 total time= 1.1min\n",
            "[CV 1/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.769 total time= 1.9min\n",
            "[CV 2/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.764 total time= 1.9min\n",
            "[CV 3/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n",
            "[CV 3/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.770 total time= 1.8min\n",
            "[CV 4/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n",
            "[CV 4/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.770 total time= 1.7min\n",
            "[CV 5/5; 6/6] START estimator__alpha=1, estimator__loss=log.....................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5; 6/6] END estimator__alpha=1, estimator__loss=log;, score=0.763 total time= 2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                                       ('estimator',\n",
              "                                        SGDClassifier(max_iter=10,\n",
              "                                                      random_state=42))]),\n",
              "             n_jobs=1,\n",
              "             param_grid=[{'estimator__alpha': [0.0001, 0.01, 1],\n",
              "                          'estimator__loss': ['hinge', 'log']}],\n",
              "             verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_['std_test_score'], \n",
        "                                  columns=[\"Std\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], \n",
        "                                  columns=[\"Score\"])],axis=1)\n",
        "\n",
        "results.sort_values(\"Score\", ascending=False)"
      ],
      "metadata": {
        "id": "i8gj3F8t9IsH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "221a8b9d-c126-43df-e6d0-c33529f4ba9c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0481522d-b62c-4a3f-adb1-4e84516fca9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator__alpha</th>\n",
              "      <th>estimator__loss</th>\n",
              "      <th>Std</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.001893</td>\n",
              "      <td>0.842398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>log</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>0.841509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>log</td>\n",
              "      <td>0.002150</td>\n",
              "      <td>0.822813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.001352</td>\n",
              "      <td>0.822530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.002284</td>\n",
              "      <td>0.793620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>log</td>\n",
              "      <td>0.003075</td>\n",
              "      <td>0.767272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0481522d-b62c-4a3f-adb1-4e84516fca9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0481522d-b62c-4a3f-adb1-4e84516fca9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0481522d-b62c-4a3f-adb1-4e84516fca9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   estimator__alpha estimator__loss       Std     Score\n",
              "2            0.0100           hinge  0.001893  0.842398\n",
              "3            0.0100             log  0.001088  0.841509\n",
              "1            0.0001             log  0.002150  0.822813\n",
              "0            0.0001           hinge  0.001352  0.822530\n",
              "4            1.0000           hinge  0.002284  0.793620\n",
              "5            1.0000             log  0.003075  0.767272"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinaremos um modelo com os melhores parametros do GridSearch:"
      ],
      "metadata": {
        "id": "eRcFq5N0DPDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ])\n",
        "\n",
        "model.set_params(**grid_search.best_params_)"
      ],
      "metadata": {
        "id": "ILqrXka19bg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c81b04-7da4-497c-9c49-5d87814c90a4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                ('estimator',\n",
              "                 SGDClassifier(alpha=0.01, max_iter=10, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_augmented, y_train_augmented)"
      ],
      "metadata": {
        "id": "bJl5a4fE9pOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c416561-31ca-4a12-b49d-a70b4272930f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                ('estimator',\n",
              "                 SGDClassifier(alpha=0.01, max_iter=10, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forçando o SGD a usar esquema OvO:"
      ],
      "metadata": {
        "id": "FTcky-m1DdeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 1000, random_state=42))\n",
        "             ])\n",
        "\n",
        "model.set_params(**grid_search.best_params_)\n",
        "ovo_clf = OneVsOneClassifier(model)"
      ],
      "metadata": {
        "id": "nKDeqTCR9814"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizaremos uma validação do modelo usando a validação cruzada:"
      ],
      "metadata": {
        "id": "9QRG4IoaDlGB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAfueZg9-Kpq"
      },
      "source": [
        "scores2 = cross_val_score(ovo_clf, X_train_augmented, y_train_augmented, cv=5)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores2\n",
        "np.mean(scores2)"
      ],
      "metadata": {
        "id": "UMemEi2Y_qFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ded794-fc29-47b8-85d5-da2163d0813a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.910625925925926"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ji3UGT_tn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2f05fd-cb23-4ffd-e8db-102a3403af94"
      },
      "source": [
        "ovo_clf.fit(X_train_augmented, y_train_augmented)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsOneClassifier(estimator=Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                                             ('estimator',\n",
              "                                              SGDClassifier(alpha=0.01,\n",
              "                                                            random_state=42))]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ovo_clf.predict(X_test)\n",
        "conf_mx = confusion_matrix(y_test, y_pred)\n",
        "conf_mx"
      ],
      "metadata": {
        "id": "Xtiq5_Qa_5jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95076714-4d3c-4bb9-d6c2-2e81e7a87c3b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 970,    1,    0,    0,    2,    3,    0,    1,    2,    1],\n",
              "       [   0, 1121,    4,    1,    1,    1,    5,    0,    2,    0],\n",
              "       [  10,    1,  966,    6,   10,    1,   12,    6,   18,    2],\n",
              "       [   2,    4,   11,  935,    2,   21,    0,    9,   23,    3],\n",
              "       [   1,    4,    4,    0,  943,    0,    8,    3,    1,   18],\n",
              "       [  10,    2,    6,   30,   11,  802,    7,    1,   19,    4],\n",
              "       [  12,    2,    7,    0,    5,   10,  920,    0,    2,    0],\n",
              "       [   3,    4,   18,    5,    6,    0,    1,  960,    1,   30],\n",
              "       [   8,    7,    4,   11,    8,   24,    3,    5,  900,    4],\n",
              "       [   7,    9,    2,   13,   22,    2,    0,   18,    7,  929]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "eZ-kbVLz_81o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ba94e6-5d09-4d7a-ca2e-21e809628662"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9446"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois da introdução de translações no conjunto de treinamento houve um aumento de mais de 2% na acurácia!"
      ],
      "metadata": {
        "id": "HZcWcFDwD5Cv"
      }
    }
  ]
}